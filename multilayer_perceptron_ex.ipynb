{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "input_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 5s 0us/step\n",
      "17473536/17464789 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s and with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with and film want an\n"
     ]
    }
   ],
   "source": [
    "print(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=input_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=input_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               4000250   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=input_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 0.4719 - accuracy: 0.7515 - val_loss: 0.2938 - val_accuracy: 0.8766\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.1735 - accuracy: 0.9356 - val_loss: 0.3211 - val_accuracy: 0.8670\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 17s 84ms/step - loss: 0.0537 - accuracy: 0.9853 - val_loss: 0.4071 - val_accuracy: 0.8644\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.5061 - val_accuracy: 0.8623\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.5741 - val_accuracy: 0.8617\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 18s 90ms/step - loss: 6.4134e-04 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8633\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 19s 96ms/step - loss: 3.5107e-04 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.8632\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 19s 96ms/step - loss: 2.3784e-04 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8644\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 19s 96ms/step - loss: 1.7025e-04 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8645\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 20s 102ms/step - loss: 1.2782e-04 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8650\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 21s 109ms/step - loss: 9.9309e-05 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8645\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 7.8415e-05 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8644\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 6.3263e-05 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8646\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 5.1290e-05 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.8651\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 4.2261e-05 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8646\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 3.5148e-05 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.8647\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 2.9332e-05 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8648\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 2.4804e-05 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.8649\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 2.0971e-05 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.8648\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 21s 108ms/step - loss: 1.7865e-05 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.8651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213debed9d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=20, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('perception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('perception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 0.8100 - accuracy: 0.8651\n",
      "Accuracy: 86.51%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 0.8100 - accuracy: 0.8651\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "\tprint(predictions[i][0] == y_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95a22eaad15357b8581a3e85dc7deb44b392b83f2a0c98c7572069d11874febe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
